{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion Search — Indexation ASOS depuis Colab (GPU)\n",
    "\n",
    "Ce notebook indexe le dataset [ASOS e-commerce](https://huggingface.co/datasets/UniqueData/asos-e-commerce-dataset) dans Weaviate en utilisant [Fashion CLIP](https://huggingface.co/patrickjohncyh/fashion-clip) sur GPU Colab.\n",
    "\n",
    "**Architecture :**\n",
    "- **Colab (GPU)** : encode les images avec Fashion CLIP → pousse les vecteurs dans Weaviate\n",
    "- **GCP (CPU)** : Weaviate + app FastAPI pour servir les recherches\n",
    "\n",
    "**Prérequis :**\n",
    "- Runtime GPU activé (Runtime → Change runtime type → T4 GPU)\n",
    "- Weaviate accessible sur ta VM GCP (port 8080 ouvert dans le firewall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation des dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q weaviate-client>=4.0 transformers torch torchvision Pillow datasets requests tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Renseigne l'IP externe de ta VM GCP où tourne Weaviate.\n",
    "\n",
    "**Important** : le port `8080` (HTTP) et `50051` (gRPC) doivent être ouverts dans le firewall GCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "GCP_EXTERNAL_IP = \"\"   # ex: \"34.56.78.90\"\n",
    "\n",
    "WEAVIATE_HTTP_PORT = 8080\n",
    "WEAVIATE_GRPC_PORT = 50051\n",
    "\n",
    "COLLECTION_NAME = \"FashionCollection\"\n",
    "MODEL_NAME = \"patrickjohncyh/fashion-clip\"\n",
    "\n",
    "MAX_ITEMS = 2000              # produits à indexer (None = tout le dataset)\n",
    "MAX_IMAGES_PER_PRODUCT = 1    # images par produit\n",
    "BATCH_SIZE = 32               # taille des batches GPU\n",
    "WEAVIATE_BATCH_SIZE = 100     # taille des batches Weaviate\n",
    "THUMBNAIL_SIZE = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vérification GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_mem / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Pas de GPU, l'indexation sera lente.\")\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chargement du modèle Fashion CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPModel, CLIPProcessor\n",
    "\n",
    "print(f\"Chargement de {MODEL_NAME}...\")\n",
    "model = CLIPModel.from_pretrained(MODEL_NAME)\n",
    "processor = CLIPProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "if device == \"cuda\":\n",
    "    model = model.half()  # FP16\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "VECTOR_DIM = model.config.projection_dim\n",
    "print(f\"Modele charge - dimension vecteur: {VECTOR_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Connexion a Weaviate sur GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.config import Configure, DataType, Property, VectorDistances\n",
    "\n",
    "assert GCP_EXTERNAL_IP, \"Renseigne GCP_EXTERNAL_IP dans la cellule de configuration.\"\n",
    "\n",
    "client = weaviate.connect_to_custom(\n",
    "    http_host=GCP_EXTERNAL_IP,\n",
    "    http_port=WEAVIATE_HTTP_PORT,\n",
    "    http_secure=False,\n",
    "    grpc_host=GCP_EXTERNAL_IP,\n",
    "    grpc_port=WEAVIATE_GRPC_PORT,\n",
    "    grpc_secure=False,\n",
    ")\n",
    "\n",
    "print(f\"Connecte a Weaviate sur {GCP_EXTERNAL_IP}\" if client.is_ready() else \"Echec de connexion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creation du schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprime et recree la collection\n",
    "if client.collections.exists(COLLECTION_NAME):\n",
    "    client.collections.delete(COLLECTION_NAME)\n",
    "    print(f\"Collection '{COLLECTION_NAME}' supprimee.\")\n",
    "\n",
    "client.collections.create(\n",
    "    name=COLLECTION_NAME,\n",
    "    properties=[\n",
    "        Property(name=\"filename\", data_type=DataType.TEXT),\n",
    "        Property(name=\"path\", data_type=DataType.TEXT),\n",
    "        Property(name=\"thumbnail_base64\", data_type=DataType.TEXT),\n",
    "        Property(name=\"width\", data_type=DataType.INT),\n",
    "        Property(name=\"height\", data_type=DataType.INT),\n",
    "        Property(name=\"indexed_at\", data_type=DataType.TEXT),\n",
    "        Property(name=\"product_id\", data_type=DataType.TEXT),\n",
    "        Property(name=\"product_name\", data_type=DataType.TEXT),\n",
    "        Property(name=\"category\", data_type=DataType.TEXT),\n",
    "        Property(name=\"color\", data_type=DataType.TEXT),\n",
    "        Property(name=\"size\", data_type=DataType.TEXT),\n",
    "        Property(name=\"price\", data_type=DataType.NUMBER),\n",
    "        Property(name=\"brand\", data_type=DataType.TEXT),\n",
    "        Property(name=\"product_url\", data_type=DataType.TEXT),\n",
    "        Property(name=\"description\", data_type=DataType.TEXT),\n",
    "        Property(name=\"image_index\", data_type=DataType.INT),\n",
    "        Property(name=\"gender\", data_type=DataType.TEXT),\n",
    "    ],\n",
    "    vectorizer_config=Configure.Vectorizer.none(),\n",
    "    vector_index_config=Configure.VectorIndex.hnsw(\n",
    "        distance_metric=VectorDistances.COSINE\n",
    "    ),\n",
    ")\n",
    "print(f\"Collection '{COLLECTION_NAME}' creee (dim={VECTOR_DIM}).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Chargement du dataset ASOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Chargement du dataset ASOS...\")\n",
    "dataset = load_dataset(\"UniqueData/asos-e-commerce-dataset\", split=\"train\")\n",
    "print(f\"Dataset charge: {len(dataset)} produits\")\n",
    "\n",
    "if MAX_ITEMS:\n",
    "    dataset = dataset.select(range(min(MAX_ITEMS, len(dataset))))\n",
    "    print(f\"Limite a {len(dataset)} produits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def parse_price(price_str):\n",
    "    if not price_str:\n",
    "        return None\n",
    "    try:\n",
    "        return float(str(price_str).strip().replace(\"\\u00a3\", \"\").replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "    except (ValueError, AttributeError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_description(desc_str):\n",
    "    if not desc_str:\n",
    "        return None, None\n",
    "    try:\n",
    "        data = json.loads(desc_str)\n",
    "        if isinstance(data, dict):\n",
    "            return data.get(\"brand\") or data.get(\"Brand\"), data.get(\"description\") or data.get(\"Description\") or str(data)\n",
    "        return None, str(data)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return None, str(desc_str)\n",
    "\n",
    "\n",
    "def parse_images(images_str):\n",
    "    if not images_str:\n",
    "        return []\n",
    "    try:\n",
    "        data = json.loads(images_str)\n",
    "        if isinstance(data, list):\n",
    "            return [u for u in data if isinstance(u, str) and u.startswith(\"http\")]\n",
    "        if isinstance(data, str) and data.startswith(\"http\"):\n",
    "            return [data]\n",
    "        return []\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        if isinstance(images_str, str) and images_str.startswith(\"http\"):\n",
    "            return [images_str]\n",
    "        return []\n",
    "\n",
    "\n",
    "def detect_gender(product_name, category):\n",
    "    text = f\"{product_name} {category}\".lower()\n",
    "    for kw in [\"women's\", \"womens\", \"female\", \"femme\", \" woman \", \"for women\", \"ladies\", \"maternity\"]:\n",
    "        if kw in text:\n",
    "            return \"women\"\n",
    "    for kw in [\"men's\", \"mens\", \"male\", \"homme\", \" man \", \"for men\"]:\n",
    "        if kw in text:\n",
    "            return \"men\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def download_image(url, timeout=10):\n",
    "    try:\n",
    "        r = requests.get(url, timeout=timeout, stream=True)\n",
    "        r.raise_for_status()\n",
    "        return Image.open(io.BytesIO(r.content)).convert(\"RGB\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def make_thumbnail_b64(image, size=THUMBNAIL_SIZE):\n",
    "    img = image.copy()\n",
    "    img.thumbnail((size, size))\n",
    "    if img.mode in (\"RGBA\", \"P\"):\n",
    "        img = img.convert(\"RGB\")\n",
    "    buf = io.BytesIO()\n",
    "    img.save(buf, format=\"JPEG\", quality=85)\n",
    "    return base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def encode_images_batch(images):\n",
    "    with torch.no_grad():\n",
    "        inputs = processor(images=images, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        features = model.get_image_features(**inputs)\n",
    "        features = features / features.norm(p=2, dim=-1, keepdim=True)\n",
    "    return features.cpu().float().numpy()\n",
    "\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Indexation (GPU batch encoding → Weaviate sur GCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "collection = client.collections.get(COLLECTION_NAME)\n",
    "\n",
    "image_batch = []\n",
    "meta_batch = []\n",
    "weaviate_queue = []\n",
    "\n",
    "indexed = 0\n",
    "skipped = 0\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "def flush_gpu_batch():\n",
    "    global image_batch, meta_batch\n",
    "    if not image_batch:\n",
    "        return\n",
    "    vectors = encode_images_batch(image_batch)\n",
    "    for vec, meta in zip(vectors, meta_batch):\n",
    "        meta[\"vector\"] = vec.tolist()\n",
    "        weaviate_queue.append(meta)\n",
    "    image_batch = []\n",
    "    meta_batch = []\n",
    "\n",
    "\n",
    "def flush_weaviate():\n",
    "    global weaviate_queue, indexed\n",
    "    if not weaviate_queue:\n",
    "        return\n",
    "    with collection.batch.dynamic() as batch:\n",
    "        for doc in weaviate_queue:\n",
    "            vec = doc.pop(\"vector\")\n",
    "            batch.add_object(properties=doc, vector=vec)\n",
    "    indexed += len(weaviate_queue)\n",
    "    weaviate_queue = []\n",
    "\n",
    "\n",
    "pbar = tqdm(total=len(dataset), desc=\"Indexation\")\n",
    "\n",
    "for item in dataset:\n",
    "    product_id = str(item.get(\"id\", item.get(\"Unnamed: 0\", \"\")))\n",
    "    product_name = item.get(\"product_name\", item.get(\"name\", \"\"))\n",
    "    category = item.get(\"category\", item.get(\"product_type\", \"\"))\n",
    "    color = item.get(\"colour\", item.get(\"color\", \"\"))\n",
    "    price = parse_price(item.get(\"price\", item.get(\"current_price\", \"\")))\n",
    "    product_url = item.get(\"url\", item.get(\"product_url\", \"\"))\n",
    "\n",
    "    brand_parsed, desc_text = parse_description(item.get(\"description\", \"\"))\n",
    "    brand = brand_parsed or item.get(\"brand\", \"\")\n",
    "    description = desc_text or \"\"\n",
    "\n",
    "    image_urls = parse_images(str(item.get(\"images\", item.get(\"image\", \"\"))))\n",
    "    gender = detect_gender(product_name or \"\", category or \"\")\n",
    "\n",
    "    product_has_image = False\n",
    "\n",
    "    for idx, url in enumerate(image_urls[:MAX_IMAGES_PER_PRODUCT]):\n",
    "        img = download_image(url)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        product_has_image = True\n",
    "        w, h = img.size\n",
    "\n",
    "        meta = {\n",
    "            \"filename\": f\"{product_id}_{idx}.jpg\",\n",
    "            \"path\": url,\n",
    "            \"thumbnail_base64\": make_thumbnail_b64(img),\n",
    "            \"width\": w,\n",
    "            \"height\": h,\n",
    "            \"indexed_at\": datetime.utcnow().isoformat(),\n",
    "            \"product_id\": product_id,\n",
    "            \"product_name\": product_name or \"\",\n",
    "            \"category\": category or \"\",\n",
    "            \"color\": color or \"\",\n",
    "            \"price\": price,\n",
    "            \"brand\": brand or \"\",\n",
    "            \"product_url\": product_url or \"\",\n",
    "            \"description\": description,\n",
    "            \"image_index\": idx,\n",
    "            \"gender\": gender,\n",
    "        }\n",
    "\n",
    "        image_batch.append(img)\n",
    "        meta_batch.append(meta)\n",
    "\n",
    "        if len(image_batch) >= BATCH_SIZE:\n",
    "            flush_gpu_batch()\n",
    "\n",
    "        if len(weaviate_queue) >= WEAVIATE_BATCH_SIZE:\n",
    "            flush_weaviate()\n",
    "\n",
    "    if not product_has_image:\n",
    "        skipped += 1\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "flush_gpu_batch()\n",
    "flush_weaviate()\n",
    "\n",
    "pbar.close()\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Indexation terminee !\")\n",
    "print(f\"Images indexees: {indexed}\")\n",
    "print(f\"Produits sans image: {skipped}\")\n",
    "print(f\"Temps: {elapsed:.0f}s ({indexed / max(elapsed, 1):.1f} images/sec)\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.collections.get(COLLECTION_NAME)\n",
    "stats = collection.aggregate.over_all(total_count=True)\n",
    "print(f\"Collection '{COLLECTION_NAME}': {stats.total_count} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Test rapide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.query import MetadataQuery\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "query = \"black leather jacket\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = processor(text=[query], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    features = model.get_text_features(**inputs)\n",
    "    features = features / features.norm(p=2, dim=-1, keepdim=True)\n",
    "    query_vector = features.cpu().float().numpy().flatten().tolist()\n",
    "\n",
    "results = collection.query.near_vector(\n",
    "    near_vector=query_vector,\n",
    "    limit=5,\n",
    "    return_metadata=MetadataQuery(distance=True),\n",
    ")\n",
    "\n",
    "print(f\"Resultats pour: '{query}'\\n\")\n",
    "\n",
    "html = '<div style=\"display:flex; gap:10px; flex-wrap:wrap;\">'\n",
    "for obj in results.objects:\n",
    "    p = obj.properties\n",
    "    score = f\"{1 - (obj.metadata.distance or 0):.3f}\"\n",
    "    thumb = p.get(\"thumbnail_base64\", \"\")\n",
    "    name = p.get(\"product_name\", \"\")\n",
    "    price = p.get(\"price\")\n",
    "    price_str = f\"\\u00a3{price:.2f}\" if price else \"\"\n",
    "    html += f'''\n",
    "    <div style=\"text-align:center; width:160px;\">\n",
    "        <img src=\"data:image/jpeg;base64,{thumb}\" style=\"max-width:150px; max-height:150px;\"/>\n",
    "        <div style=\"font-size:11px;\">{name[:40]}</div>\n",
    "        <div style=\"font-size:11px; color:gray;\">{price_str} - score: {score}</div>\n",
    "    </div>'''\n",
    "html += '</div>'\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "print(\"Connexion Weaviate fermee.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}